{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS181_P1 Tuning Model on New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...   2038  2039  2040  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   0.0   \n",
       "4  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   0.0   \n",
       "\n",
       "   2041  2042  2043  2044  2045  2046  2047  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 2048 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fp_train_sub7 = pd.read_csv(\"X_fp_train_sub7.csv\")\n",
    "X_fp_train_sub7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0  1.57\n",
       "1  1.76\n",
       "2  1.41\n",
       "3  2.80\n",
       "4  1.46"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_fp_train_sub7 = pd.read_csv(\"Y_fp_train_sub7.csv\")\n",
    "Y_fp_train_sub7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_fp_train_sub7 = X_fp_train_sub7.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_fp_train_sub7 = Y_fp_train_sub7.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Feature Selection\n",
    "### 1. split data into test and training subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_fp_train_sub7, Y_fp_train_sub7, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train:  (100000, 2048)\n",
      "shape of x_test:  (25000, 2048)\n",
      "shape of y_train:  (100000, 1)\n",
      "shape of y_test:  (25000, 1)\n"
     ]
    }
   ],
   "source": [
    "# see the shape of data after split:\n",
    "print(\"shape of x_train: \", x_train.shape)\n",
    "print(\"shape of x_test: \", x_test.shape)\n",
    "print(\"shape of y_train: \", y_train.shape)\n",
    "print(\"shape of y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. fit baseline model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# 1.Random Forest\n",
    "# 1.1 fit the model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RF = RandomForestRegressor().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for training set is:  0.987748082947\n",
      "R^2 for test set is:  0.935560637534\n",
      "MSE for training set is:  0.00203335191227\n",
      "MSE for test set is:  0.0106719967537\n"
     ]
    }
   ],
   "source": [
    "# 1.2 report R^2 for training and test\n",
    "print(\"R^2 for training set is: \", r2_score(y_train, RF.predict(x_train)))\n",
    "print(\"R^2 for test set is: \", r2_score(y_test, RF.predict(x_test)))\n",
    "print(\"MSE for training set is: \", mean_squared_error(y_train, RF.predict(x_train)))\n",
    "print(\"MSE for test set is: \", mean_squared_error(y_test, RF.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Drop features with importance = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features after 1 drop: (100000, 1702)\n",
      "Train gap: (100000, 1)\n",
      "Test features after 1 drop: (25000, 1702)\n"
     ]
    }
   ],
   "source": [
    "RF_imp = RF.feature_importances_\n",
    "i0 = (RF_imp == 0)\n",
    "x_train_1 = x_train[:,i0 == False]\n",
    "x_test_1 = x_test[:,i0 == False]\n",
    "# view data structure after drop\n",
    "print(\"Train features after 1 drop:\", x_train_1.shape)\n",
    "print(\"Train gap:\", y_train.shape)\n",
    "print(\"Test features after 1 drop:\", x_test_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. refit baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "RF_1 = RandomForestRegressor().fit(x_train_1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for training set is:  0.987802431927\n",
      "R^2 for test set is:  0.935891401396\n",
      "MSE for training set is:  0.0020243320501\n",
      "MSE for test set is:  0.0106172179551\n"
     ]
    }
   ],
   "source": [
    "print(\"R^2 for training set is: \", r2_score(y_train, RF_1.predict(x_train_1)))\n",
    "print(\"R^2 for test set is: \", r2_score(y_test, RF_1.predict(x_test_1)))\n",
    "print(\"MSE for training set is: \", mean_squared_error(y_train, RF_1.predict(x_train_1)))\n",
    "print(\"MSE for test set is: \", mean_squared_error(y_test, RF_1.predict(x_test_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. further drop features with importance < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features after 1 drop: (100000, 1702)\n",
      "Train gap: (100000, 1)\n",
      "Test features after 1 drop: (25000, 1702)\n"
     ]
    }
   ],
   "source": [
    "RF_imp_1 = RF_1.feature_importances_\n",
    "i1 = (RF_imp_1 <= 0)\n",
    "x_train_2 = x_train_1[:,i1 == False]\n",
    "x_test_2 = x_test_1[:,i1 == False]\n",
    "# view data structure after drop\n",
    "print(\"Train features after 1 drop:\", x_train_1.shape)\n",
    "print(\"Train gap:\", y_train.shape)\n",
    "print(\"Test features after 1 drop:\", x_test_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary: we can't drop much by \"importance <=0:\"\n",
    "\n",
    "#### 2048 -> 1699"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. plot the distribution of features importance\n",
    "- see whether we can drop more by setting threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEaCAYAAAAL7cBuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqryDW1cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114ab3da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(RF_imp_1, bins ='auto')\n",
    "plt.title(\"Histogram with 'feature_importances'\")\n",
    "plt.xscale('log')\n",
    "plt.xlabel(\"Impotance\")\n",
    "plt.ylabel(\"Counts of Features\")\n",
    "plt.savefig('his_feature_importance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbgAAAD+CAYAAABIvBB2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118167cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(len(RF_1.feature_importances_)), RF_1.feature_importances_, 2)\n",
    "plt.yscale('symlog')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary: scince more importance are relatively small, it's risky to drop more features by setting up threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Tune Hyper parameters via 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py:645: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  best_estimator.fit(X, y, **self.fit_params)\n",
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:17: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "parameters = {#\"max_depth\": [150,450,750,1050,1350,1650]\n",
    "                        #,\"min_samples_split\" :[2,10,50,500,1000]\n",
    "                        \"n_estimators\" : [5, 10, 20]}\n",
    "                        #,\"min_samples_leaf\": [2,10,50,500,1000]\n",
    "                        #,\"max_features\": ('auto','sqrt','log2')\n",
    "rf_regr = RandomForestRegressor()\n",
    "model = GridSearchCV(rf_regr,parameters, cv = 5)\n",
    "fit = model.fit(x_train_1,y_train)\n",
    "learned_parameters = fit.best_params_ \n",
    "# Rerun model on fitted parameters \n",
    "rfr = RandomForestRegressor(#max_depth = learned_parameters[\"max_depth\"]\n",
    "                            max_features = 'sqrt'\n",
    "                            #,min_samples_leaf = learned_parameters['min_samples_leaf']\n",
    "                            #,min_samples_split = learned_parameters['min_samples_split']\n",
    "                            ,n_estimators = learned_parameters['n_estimators']\n",
    "                            ,random_state = 78)\n",
    "rfr_fit = rfr.fit(x_train_1,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for training set is:  0.98556747146\n",
      "R^2 for test set is:  0.919003528197\n",
      "MSE for training set is:  0.00239525042309\n",
      "MSE for test set is:  0.0134140694611\n"
     ]
    }
   ],
   "source": [
    "print(\"R^2 for training set is: \", r2_score(y_train, rfr_fit.predict(x_train_1)))\n",
    "print(\"R^2 for test set is: \", r2_score(y_test, rfr_fit.predict(x_test_1)))\n",
    "print(\"MSE for training set is: \", mean_squared_error(y_train, rfr_fit.predict(x_train_1)))\n",
    "print(\"MSE for test set is: \", mean_squared_error(y_test, rfr_fit.predict(x_test_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 'number of estimator' is:  20\n"
     ]
    }
   ],
   "source": [
    "print(\"Best 'number of estimator' is: \", learned_parameters['n_estimators'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would always choose the largest number of estimator, to kill more varriance, we just need to choose the reasonable one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file(\"Xihan.csv\", RF_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file(filename, predictions):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i,p in enumerate(predictions):\n",
    "            f.write(str(i+1) + \",\" + str(p) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
